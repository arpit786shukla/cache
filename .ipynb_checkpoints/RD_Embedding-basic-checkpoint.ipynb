{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import defaultdict \n",
    "import sys\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from tabulate import tabulate\n",
    "import time\n",
    "import keras \n",
    "from keras.models import Sequential, Model, load_model\n",
    "from keras.layers import Dense, Input, Dropout, Embedding, LSTM, Flatten, Lambda\n",
    "from sklearn.preprocessing import OneHotEncoder, MinMaxScaler\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "\n",
    "from keras.utils import to_categorical\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from keras.utils.vis_utils import plot_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "ADDR = '/nfs_home/nbhardwaj/data/rds_final/'\n",
    "w_ADDR = '/nfs_home/nbhardwaj/model_weights/finalwts/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "class LabelEncoderExt(object):\n",
    "    def __init__(self):\n",
    "        \"\"\"\n",
    "        It differs from LabelEncoder by handling new classes and providing a value for it [Unknown]\n",
    "        Unknown will be added in fit and transform will take care of new item. It gives unknown class id\n",
    "        \"\"\"\n",
    "        self.label_encoder = LabelEncoder()\n",
    "        # self.classes_ = self.label_encoder.classes_\n",
    "\n",
    "    def fit(self, data_list):\n",
    "        \"\"\"\n",
    "        This will fit the encoder for all the unique values and introduce unknown value\n",
    "        :param data_list: A list of string\n",
    "        :return: self\n",
    "        \"\"\"\n",
    "        self.label_encoder = self.label_encoder.fit(list(data_list) + ['Unknown'])\n",
    "        self.classes_ = self.label_encoder.classes_\n",
    "\n",
    "        return self\n",
    "\n",
    "    def transform(self, data_list):\n",
    "        \"\"\"\n",
    "        This will transform the data_list to id list where the new values get assigned to Unknown class\n",
    "        :param data_list:\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        new_data_list = list(data_list)\n",
    "        m = {}\n",
    "        for x in self.label_encoder.classes_:\n",
    "            m[x] = True\n",
    "        for ind, y in enumerate(new_data_list):\n",
    "            if(m.get(y) is None):\n",
    "                new_data_list[ind] = 'Unknown'\n",
    "#         for unique_item in np.unique(data_list):\n",
    "#             if unique_item not in self.label_encoder.classes_:\n",
    "#                 new_data_list = ['Unknown' if x==unique_item else x for x in new_data_list]\n",
    "        return self.label_encoder.transform(new_data_list)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(embed_size = 10):\n",
    "    inp1 = Input(shape = (1,))\n",
    "    inp2 = Input(shape = (1,))\n",
    "    # inp3 = Input(shape = (1,))\n",
    "\n",
    "    embed1 = Embedding(len(le_inst.classes_), embed_size, input_length = 1)(inp1)\n",
    "    embed2 = Embedding(len(le_delta.classes_), embed_size, input_length = 1)(inp2)\n",
    "\n",
    "    merged_inp = keras.layers.concatenate([embed1, embed2], axis = 1)\n",
    "    merged_inp = Flatten()(merged_inp)\n",
    "    # merged_inp = keras.layers.concatenate([merged_inp, inp3])\n",
    "    \n",
    "#     out = LSTM(64)(merged_inp)\n",
    "    out = Dense(32, activation = 'relu')(merged_inp)\n",
    "    out = Dense(8, activation = 'softmax')(out)\n",
    "\n",
    "    model = Model([inp1, inp2], out)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------split done---------------------\n",
      "----------------labels done----------------------\n",
      "--------\n",
      "-------------------labels transformed---------------------\n",
      "WARNING:tensorflow:From /nfs_home/nbhardwaj/.local/lib/python3.5/site-packages/keras/backend/tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "Train on 479 samples, validate on 120 samples\n",
      "Epoch 1/50\n",
      "479/479 [==============================] - 0s 416us/step - loss: 2.0657 - accuracy: 0.3278 - val_loss: 2.0459 - val_accuracy: 0.9333\n",
      "Epoch 2/50\n",
      "479/479 [==============================] - 0s 29us/step - loss: 2.0392 - accuracy: 0.8914 - val_loss: 2.0183 - val_accuracy: 0.9333\n",
      "Epoch 3/50\n",
      "479/479 [==============================] - 0s 29us/step - loss: 2.0133 - accuracy: 0.8914 - val_loss: 1.9915 - val_accuracy: 0.9333\n",
      "Epoch 4/50\n",
      "479/479 [==============================] - 0s 26us/step - loss: 1.9876 - accuracy: 0.8914 - val_loss: 1.9631 - val_accuracy: 0.9333\n",
      "Epoch 5/50\n",
      "479/479 [==============================] - 0s 23us/step - loss: 1.9596 - accuracy: 0.8914 - val_loss: 1.9326 - val_accuracy: 0.9333\n",
      "Epoch 6/50\n",
      "479/479 [==============================] - 0s 25us/step - loss: 1.9304 - accuracy: 0.8914 - val_loss: 1.8998 - val_accuracy: 0.9333\n",
      "Epoch 7/50\n",
      "479/479 [==============================] - 0s 27us/step - loss: 1.8987 - accuracy: 0.8914 - val_loss: 1.8639 - val_accuracy: 0.9333\n",
      "Epoch 8/50\n",
      "479/479 [==============================] - 0s 27us/step - loss: 1.8637 - accuracy: 0.8914 - val_loss: 1.8239 - val_accuracy: 0.9333\n",
      "Epoch 9/50\n",
      "479/479 [==============================] - 0s 29us/step - loss: 1.8244 - accuracy: 0.8914 - val_loss: 1.7795 - val_accuracy: 0.9333\n",
      "Epoch 10/50\n",
      "479/479 [==============================] - 0s 31us/step - loss: 1.7809 - accuracy: 0.8914 - val_loss: 1.7307 - val_accuracy: 0.9333\n",
      "Epoch 11/50\n",
      "479/479 [==============================] - 0s 22us/step - loss: 1.7335 - accuracy: 0.8914 - val_loss: 1.6767 - val_accuracy: 0.9333\n",
      "Epoch 12/50\n",
      "479/479 [==============================] - 0s 30us/step - loss: 1.6810 - accuracy: 0.8914 - val_loss: 1.6175 - val_accuracy: 0.9333\n",
      "Epoch 13/50\n",
      "479/479 [==============================] - 0s 30us/step - loss: 1.6238 - accuracy: 0.8914 - val_loss: 1.5531 - val_accuracy: 0.9333\n",
      "Epoch 14/50\n",
      "479/479 [==============================] - 0s 32us/step - loss: 1.5614 - accuracy: 0.8914 - val_loss: 1.4838 - val_accuracy: 0.9333\n",
      "Epoch 15/50\n",
      "479/479 [==============================] - 0s 29us/step - loss: 1.4937 - accuracy: 0.8914 - val_loss: 1.4098 - val_accuracy: 0.9333\n",
      "Epoch 16/50\n",
      "479/479 [==============================] - 0s 31us/step - loss: 1.4230 - accuracy: 0.8914 - val_loss: 1.3305 - val_accuracy: 0.9333\n",
      "Epoch 17/50\n",
      "479/479 [==============================] - 0s 26us/step - loss: 1.3460 - accuracy: 0.8914 - val_loss: 1.2475 - val_accuracy: 0.9333\n",
      "Epoch 18/50\n",
      "479/479 [==============================] - 0s 27us/step - loss: 1.2673 - accuracy: 0.8914 - val_loss: 1.1607 - val_accuracy: 0.9333\n",
      "Epoch 19/50\n",
      "479/479 [==============================] - 0s 28us/step - loss: 1.1852 - accuracy: 0.8914 - val_loss: 1.0718 - val_accuracy: 0.9333\n",
      "Epoch 20/50\n",
      "479/479 [==============================] - 0s 25us/step - loss: 1.1004 - accuracy: 0.8914 - val_loss: 0.9823 - val_accuracy: 0.9333\n",
      "Epoch 21/50\n",
      "479/479 [==============================] - 0s 29us/step - loss: 1.0158 - accuracy: 0.8914 - val_loss: 0.8937 - val_accuracy: 0.9333\n",
      "Epoch 22/50\n",
      "479/479 [==============================] - 0s 29us/step - loss: 0.9340 - accuracy: 0.8914 - val_loss: 0.8075 - val_accuracy: 0.9333\n",
      "Epoch 23/50\n",
      "479/479 [==============================] - 0s 30us/step - loss: 0.8552 - accuracy: 0.8914 - val_loss: 0.7265 - val_accuracy: 0.9333\n",
      "Epoch 24/50\n",
      "479/479 [==============================] - 0s 26us/step - loss: 0.7828 - accuracy: 0.8914 - val_loss: 0.6522 - val_accuracy: 0.9333\n",
      "Epoch 25/50\n",
      "479/479 [==============================] - 0s 25us/step - loss: 0.7168 - accuracy: 0.8914 - val_loss: 0.5863 - val_accuracy: 0.9333\n",
      "Epoch 26/50\n",
      "479/479 [==============================] - 0s 29us/step - loss: 0.6589 - accuracy: 0.8914 - val_loss: 0.5298 - val_accuracy: 0.9333\n",
      "Epoch 27/50\n",
      "479/479 [==============================] - 0s 28us/step - loss: 0.6110 - accuracy: 0.8914 - val_loss: 0.4819 - val_accuracy: 0.9333\n",
      "Epoch 28/50\n",
      "479/479 [==============================] - 0s 30us/step - loss: 0.5703 - accuracy: 0.8914 - val_loss: 0.4428 - val_accuracy: 0.9333\n",
      "Epoch 29/50\n",
      "479/479 [==============================] - 0s 30us/step - loss: 0.5374 - accuracy: 0.8914 - val_loss: 0.4113 - val_accuracy: 0.9333\n",
      "Epoch 30/50\n",
      "479/479 [==============================] - 0s 32us/step - loss: 0.5110 - accuracy: 0.8914 - val_loss: 0.3862 - val_accuracy: 0.9333\n",
      "Epoch 31/50\n",
      "479/479 [==============================] - 0s 26us/step - loss: 0.4899 - accuracy: 0.8914 - val_loss: 0.3661 - val_accuracy: 0.9333\n",
      "Epoch 32/50\n",
      "479/479 [==============================] - 0s 28us/step - loss: 0.4727 - accuracy: 0.8914 - val_loss: 0.3500 - val_accuracy: 0.9333\n",
      "Epoch 33/50\n",
      "479/479 [==============================] - 0s 32us/step - loss: 0.4586 - accuracy: 0.8914 - val_loss: 0.3371 - val_accuracy: 0.9333\n",
      "Epoch 34/50\n",
      "479/479 [==============================] - 0s 29us/step - loss: 0.4469 - accuracy: 0.8914 - val_loss: 0.3266 - val_accuracy: 0.9333\n",
      "Epoch 35/50\n",
      "479/479 [==============================] - 0s 26us/step - loss: 0.4368 - accuracy: 0.8914 - val_loss: 0.3180 - val_accuracy: 0.9333\n",
      "Epoch 36/50\n",
      "479/479 [==============================] - 0s 28us/step - loss: 0.4283 - accuracy: 0.8914 - val_loss: 0.3109 - val_accuracy: 0.9333\n",
      "Epoch 37/50\n",
      "479/479 [==============================] - 0s 26us/step - loss: 0.4206 - accuracy: 0.8914 - val_loss: 0.3050 - val_accuracy: 0.9333\n",
      "Epoch 38/50\n",
      "479/479 [==============================] - 0s 25us/step - loss: 0.4137 - accuracy: 0.8914 - val_loss: 0.3000 - val_accuracy: 0.9333\n",
      "Epoch 39/50\n",
      "479/479 [==============================] - 0s 23us/step - loss: 0.4078 - accuracy: 0.8914 - val_loss: 0.2956 - val_accuracy: 0.9333\n",
      "Epoch 40/50\n",
      "479/479 [==============================] - 0s 30us/step - loss: 0.4026 - accuracy: 0.8914 - val_loss: 0.2920 - val_accuracy: 0.9333\n",
      "Epoch 41/50\n",
      "479/479 [==============================] - 0s 27us/step - loss: 0.3975 - accuracy: 0.8914 - val_loss: 0.2886 - val_accuracy: 0.9333\n",
      "Epoch 42/50\n",
      "479/479 [==============================] - 0s 26us/step - loss: 0.3933 - accuracy: 0.8914 - val_loss: 0.2858 - val_accuracy: 0.9333\n",
      "Epoch 43/50\n",
      "479/479 [==============================] - 0s 27us/step - loss: 0.3892 - accuracy: 0.8914 - val_loss: 0.2833 - val_accuracy: 0.9333\n",
      "Epoch 44/50\n",
      "479/479 [==============================] - 0s 34us/step - loss: 0.3854 - accuracy: 0.8914 - val_loss: 0.2808 - val_accuracy: 0.9333\n",
      "Epoch 45/50\n",
      "479/479 [==============================] - 0s 32us/step - loss: 0.3824 - accuracy: 0.8914 - val_loss: 0.2790 - val_accuracy: 0.9333\n",
      "Epoch 46/50\n",
      "479/479 [==============================] - 0s 28us/step - loss: 0.3791 - accuracy: 0.8914 - val_loss: 0.2770 - val_accuracy: 0.9333\n",
      "Epoch 47/50\n",
      "479/479 [==============================] - 0s 23us/step - loss: 0.3763 - accuracy: 0.8914 - val_loss: 0.2753 - val_accuracy: 0.9333\n",
      "Epoch 48/50\n",
      "479/479 [==============================] - 0s 26us/step - loss: 0.3738 - accuracy: 0.8914 - val_loss: 0.2739 - val_accuracy: 0.9333\n",
      "Epoch 49/50\n",
      "479/479 [==============================] - 0s 28us/step - loss: 0.3715 - accuracy: 0.8914 - val_loss: 0.2727 - val_accuracy: 0.9333\n",
      "Epoch 50/50\n",
      "479/479 [==============================] - 0s 26us/step - loss: 0.3694 - accuracy: 0.8914 - val_loss: 0.2717 - val_accuracy: 0.9333\n",
      "------------training done------------\n",
      "400/400 [==============================] - 0s 35us/step\n",
      "599/599 [==============================] - 0s 31us/step\n",
      "--------------done processing for set----------> 0\n",
      "|| accuracy|| 0.899833083152771 0.8899999856948853\n",
      "inst vocal 6 || delta vocal-> 15\n",
      "____________________________________________________________________________________________________\n",
      "--------------------split done---------------------\n",
      "----------------labels done----------------------\n",
      "--------\n",
      "-------------------labels transformed---------------------\n",
      "Train on 479 samples, validate on 120 samples\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "479/479 [==============================] - 0s 368us/step - loss: 2.0469 - accuracy: 0.8038 - val_loss: 2.0232 - val_accuracy: 0.9333\n",
      "Epoch 2/50\n",
      "479/479 [==============================] - 0s 26us/step - loss: 2.0132 - accuracy: 0.8894 - val_loss: 1.9862 - val_accuracy: 0.9333\n",
      "Epoch 3/50\n",
      "479/479 [==============================] - 0s 25us/step - loss: 1.9774 - accuracy: 0.8894 - val_loss: 1.9461 - val_accuracy: 0.9333\n",
      "Epoch 4/50\n",
      "479/479 [==============================] - 0s 27us/step - loss: 1.9379 - accuracy: 0.8894 - val_loss: 1.9020 - val_accuracy: 0.9333\n",
      "Epoch 5/50\n",
      "479/479 [==============================] - 0s 25us/step - loss: 1.8938 - accuracy: 0.8894 - val_loss: 1.8524 - val_accuracy: 0.9333\n",
      "Epoch 6/50\n",
      "479/479 [==============================] - 0s 28us/step - loss: 1.8449 - accuracy: 0.8894 - val_loss: 1.7969 - val_accuracy: 0.9333\n",
      "Epoch 7/50\n",
      "479/479 [==============================] - 0s 27us/step - loss: 1.7900 - accuracy: 0.8894 - val_loss: 1.7353 - val_accuracy: 0.9333\n",
      "Epoch 8/50\n",
      "479/479 [==============================] - 0s 24us/step - loss: 1.7302 - accuracy: 0.8894 - val_loss: 1.6670 - val_accuracy: 0.9333\n",
      "Epoch 9/50\n",
      "479/479 [==============================] - 0s 25us/step - loss: 1.6620 - accuracy: 0.8894 - val_loss: 1.5917 - val_accuracy: 0.9333\n",
      "Epoch 10/50\n",
      "479/479 [==============================] - 0s 25us/step - loss: 1.5869 - accuracy: 0.8894 - val_loss: 1.5073 - val_accuracy: 0.9333\n",
      "Epoch 11/50\n",
      "479/479 [==============================] - 0s 27us/step - loss: 1.5040 - accuracy: 0.8894 - val_loss: 1.4148 - val_accuracy: 0.9333\n",
      "Epoch 12/50\n",
      "479/479 [==============================] - 0s 30us/step - loss: 1.4141 - accuracy: 0.8894 - val_loss: 1.3150 - val_accuracy: 0.9333\n",
      "Epoch 13/50\n",
      "479/479 [==============================] - 0s 32us/step - loss: 1.3170 - accuracy: 0.8894 - val_loss: 1.2094 - val_accuracy: 0.9333\n",
      "Epoch 14/50\n",
      "479/479 [==============================] - 0s 27us/step - loss: 1.2161 - accuracy: 0.8894 - val_loss: 1.0985 - val_accuracy: 0.9333\n",
      "Epoch 15/50\n",
      "479/479 [==============================] - 0s 27us/step - loss: 1.1104 - accuracy: 0.8894 - val_loss: 0.9841 - val_accuracy: 0.9333\n",
      "Epoch 16/50\n",
      "479/479 [==============================] - 0s 25us/step - loss: 1.0026 - accuracy: 0.8894 - val_loss: 0.8706 - val_accuracy: 0.9333\n",
      "Epoch 17/50\n",
      "479/479 [==============================] - 0s 27us/step - loss: 0.8991 - accuracy: 0.8894 - val_loss: 0.7621 - val_accuracy: 0.9333\n",
      "Epoch 18/50\n",
      "479/479 [==============================] - 0s 25us/step - loss: 0.8007 - accuracy: 0.8894 - val_loss: 0.6639 - val_accuracy: 0.9333\n",
      "Epoch 19/50\n",
      "479/479 [==============================] - 0s 25us/step - loss: 0.7144 - accuracy: 0.8894 - val_loss: 0.5784 - val_accuracy: 0.9333\n",
      "Epoch 20/50\n",
      "479/479 [==============================] - 0s 27us/step - loss: 0.6424 - accuracy: 0.8894 - val_loss: 0.5071 - val_accuracy: 0.9333\n",
      "Epoch 21/50\n",
      "479/479 [==============================] - 0s 27us/step - loss: 0.5826 - accuracy: 0.8894 - val_loss: 0.4508 - val_accuracy: 0.9333\n",
      "Epoch 22/50\n",
      "479/479 [==============================] - 0s 25us/step - loss: 0.5372 - accuracy: 0.8894 - val_loss: 0.4074 - val_accuracy: 0.9333\n",
      "Epoch 23/50\n",
      "479/479 [==============================] - 0s 27us/step - loss: 0.5023 - accuracy: 0.8894 - val_loss: 0.3751 - val_accuracy: 0.9333\n",
      "Epoch 24/50\n",
      "479/479 [==============================] - 0s 30us/step - loss: 0.4769 - accuracy: 0.8894 - val_loss: 0.3510 - val_accuracy: 0.9333\n",
      "Epoch 25/50\n",
      "479/479 [==============================] - 0s 26us/step - loss: 0.4579 - accuracy: 0.8894 - val_loss: 0.3333 - val_accuracy: 0.9333\n",
      "Epoch 26/50\n",
      "479/479 [==============================] - 0s 30us/step - loss: 0.4434 - accuracy: 0.8894 - val_loss: 0.3199 - val_accuracy: 0.9333\n",
      "Epoch 27/50\n",
      "479/479 [==============================] - 0s 27us/step - loss: 0.4320 - accuracy: 0.8894 - val_loss: 0.3096 - val_accuracy: 0.9333\n",
      "Epoch 28/50\n",
      "479/479 [==============================] - 0s 29us/step - loss: 0.4226 - accuracy: 0.8894 - val_loss: 0.3019 - val_accuracy: 0.9333\n",
      "Epoch 29/50\n",
      "479/479 [==============================] - 0s 25us/step - loss: 0.4142 - accuracy: 0.8894 - val_loss: 0.2956 - val_accuracy: 0.9333\n",
      "Epoch 30/50\n",
      "479/479 [==============================] - 0s 28us/step - loss: 0.4069 - accuracy: 0.8894 - val_loss: 0.2904 - val_accuracy: 0.9333\n",
      "Epoch 31/50\n",
      "479/479 [==============================] - 0s 26us/step - loss: 0.4006 - accuracy: 0.8894 - val_loss: 0.2864 - val_accuracy: 0.9333\n",
      "Epoch 32/50\n",
      "479/479 [==============================] - 0s 24us/step - loss: 0.3952 - accuracy: 0.8894 - val_loss: 0.2831 - val_accuracy: 0.9333\n",
      "Epoch 33/50\n",
      "479/479 [==============================] - 0s 28us/step - loss: 0.3897 - accuracy: 0.8894 - val_loss: 0.2803 - val_accuracy: 0.9333\n",
      "Epoch 34/50\n",
      "479/479 [==============================] - 0s 27us/step - loss: 0.3851 - accuracy: 0.8894 - val_loss: 0.2779 - val_accuracy: 0.9333\n",
      "Epoch 35/50\n",
      "479/479 [==============================] - 0s 27us/step - loss: 0.3808 - accuracy: 0.8894 - val_loss: 0.2758 - val_accuracy: 0.9333\n",
      "Epoch 36/50\n",
      "479/479 [==============================] - 0s 27us/step - loss: 0.3773 - accuracy: 0.8894 - val_loss: 0.2741 - val_accuracy: 0.9333\n",
      "Epoch 37/50\n",
      "479/479 [==============================] - 0s 26us/step - loss: 0.3741 - accuracy: 0.8894 - val_loss: 0.2726 - val_accuracy: 0.9333\n",
      "Epoch 38/50\n",
      "479/479 [==============================] - 0s 29us/step - loss: 0.3709 - accuracy: 0.8894 - val_loss: 0.2710 - val_accuracy: 0.9333\n",
      "Epoch 39/50\n",
      "479/479 [==============================] - 0s 26us/step - loss: 0.3682 - accuracy: 0.8894 - val_loss: 0.2695 - val_accuracy: 0.9333\n",
      "Epoch 40/50\n",
      "479/479 [==============================] - 0s 30us/step - loss: 0.3657 - accuracy: 0.8894 - val_loss: 0.2680 - val_accuracy: 0.9333\n",
      "Epoch 41/50\n",
      "479/479 [==============================] - 0s 27us/step - loss: 0.3634 - accuracy: 0.8894 - val_loss: 0.2666 - val_accuracy: 0.9333\n",
      "Epoch 42/50\n",
      "479/479 [==============================] - 0s 31us/step - loss: 0.3613 - accuracy: 0.8894 - val_loss: 0.2655 - val_accuracy: 0.9333\n",
      "Epoch 43/50\n",
      "479/479 [==============================] - 0s 26us/step - loss: 0.3592 - accuracy: 0.8894 - val_loss: 0.2645 - val_accuracy: 0.9333\n",
      "Epoch 44/50\n",
      "479/479 [==============================] - 0s 29us/step - loss: 0.3573 - accuracy: 0.8894 - val_loss: 0.2635 - val_accuracy: 0.9333\n",
      "Epoch 45/50\n",
      "479/479 [==============================] - 0s 36us/step - loss: 0.3555 - accuracy: 0.8894 - val_loss: 0.2624 - val_accuracy: 0.9333\n",
      "Epoch 46/50\n",
      "479/479 [==============================] - 0s 28us/step - loss: 0.3540 - accuracy: 0.8894 - val_loss: 0.2615 - val_accuracy: 0.9333\n",
      "Epoch 47/50\n",
      "479/479 [==============================] - 0s 27us/step - loss: 0.3524 - accuracy: 0.8894 - val_loss: 0.2602 - val_accuracy: 0.9333\n",
      "Epoch 48/50\n",
      "479/479 [==============================] - 0s 30us/step - loss: 0.3511 - accuracy: 0.8894 - val_loss: 0.2592 - val_accuracy: 0.9333\n",
      "Epoch 49/50\n",
      "479/479 [==============================] - 0s 27us/step - loss: 0.3497 - accuracy: 0.8894 - val_loss: 0.2581 - val_accuracy: 0.9333\n",
      "Epoch 50/50\n",
      "479/479 [==============================] - 0s 26us/step - loss: 0.3485 - accuracy: 0.8894 - val_loss: 0.2572 - val_accuracy: 0.9333\n",
      "------------training done------------\n",
      "400/400 [==============================] - 0s 33us/step\n",
      "599/599 [==============================] - 0s 29us/step\n",
      "--------------done processing for set----------> 1\n",
      "|| accuracy|| 0.8981636166572571 0.8974999785423279\n",
      "inst vocal 7 || delta vocal-> 14\n",
      "____________________________________________________________________________________________________\n",
      "$$$$$$$ done for file ||------------> 510\n"
     ]
    }
   ],
   "source": [
    "files = [510\n",
    "          , 511, 526, 600, 602, 620, 623, 625, 631, 641, 648, 657\n",
    "         ]\n",
    "sets = [x for x in range(64)]\n",
    "df_m = pd.DataFrame(columns = ['fname', 'set', 'train_acc', 'test_acc', 'len', 'inst_v', 'delt_v'])\n",
    "for fname in files:\n",
    "    cw_ADDR = w_ADDR+str(fname)+'/'\n",
    "    for cset in sets:\n",
    "        if(not os.path.isdir(cw_ADDR)):\n",
    "            os.system(\"mkdir \"+cw_ADDR)\n",
    "            \n",
    "        df = pd.read_csv(ADDR+str(fname)+'_'+str(cset)+'.csv', index_col = [0], usecols = [0,2,7,8])\n",
    "        df.Instruction = df.Instruction.astype('str')\n",
    "        df.delta = df.delta.astype('float')\n",
    "\n",
    "        X = df[['Instruction', 'delta']].values[1:]\n",
    "        y = df[['label']].values[1:]\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.4, random_state = 42)\n",
    "        print(\"--------------------split done---------------------\")\n",
    "        le_inst = LabelEncoderExt()\n",
    "        le_inst.fit(X_train[:, 0])\n",
    "        le_delta = LabelEncoderExt()\n",
    "        le_delta.fit(X_train[:, 1])\n",
    "        print(\"----------------labels done----------------------\")\n",
    "        X_train[:, 0] = le_inst.transform(X_train[:, 0])\n",
    "        X_train[:, 1] = le_delta.transform(X_train[:, 1])\n",
    "        print(\"--------\")\n",
    "\n",
    "        X_test[:, 0] = le_inst.transform(X_test[:, 0])\n",
    "        X_test[:, 1] = le_delta.transform(X_test[:, 1])\n",
    "        print(\"-------------------labels transformed---------------------\")\n",
    "        filepath = cw_ADDR+str(fname)+'_'+str(cset)+'.hdf5'\n",
    "\n",
    "        if(os.path.isfile(filepath)):\n",
    "            model = load_model(filepath)\n",
    "        else:\n",
    "            model = create_model()\n",
    "            model.compile(optimizer = 'adam', loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
    "     \n",
    "        es = EarlyStopping(monitor = 'val_loss', mode = 'min', verbose = 1, patience = 2)\n",
    "        mc = ModelCheckpoint(filepath, monitor = 'val_accuracy', save_best_only = True, mode = 'max')\n",
    "        history = model.fit([X_train[:, 0], X_train[:, 1]], to_categorical(y_train), epochs = 50, \n",
    "                  validation_split = 0.2, use_multiprocessing = True, verbose = 2, callbacks = [es, mc], batch_size = 256)\n",
    "\n",
    "        print(\"------------training done------------\")\n",
    "    #     model.save_weights(filepath)\n",
    "        t_ac = model.evaluate([X_test[:, 0], X_test[:, 1]], to_categorical(y_test), verbose = 2)[1]\n",
    "        tr_ac = model.evaluate([X_train[:, 0], X_train[:, 1]], to_categorical(y_train), verbose = 2)[1]\n",
    "        \n",
    "        # need to reduce len to test_size later\n",
    "        df_m.loc[len(df_m)] = [fname, cset, tr_ac, t_ac, len(df), len(le_inst.classes_), len(le_delta.classes_)]\n",
    "\n",
    "        print(\"--------------done processing for set---------->\", cset)\n",
    "        print( '|| accuracy||', tr_ac, t_ac)\n",
    "        print(\"inst vocal\", len(le_inst.classes_), \"|| delta vocal->\", len(le_delta.classes_))\n",
    "        print(\"____________________________________________________________________________________________________\")\n",
    "    df_m.to_csv(cw_ADDR+'results.csv')\n",
    "    print(\"$$$$$$$ done for file ||------------>\", fname)\n",
    "df_m.to_csv(w_ADDR+'results.csv')\n",
    "print(\"---------ALL DONE___________\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['accuracy', 'val_accuracy', 'val_loss', 'loss'])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# history.history.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plt.plot(history.history['loss'], label = 'train')\n",
    "# plt.plot(history.history['val_loss'] , label = 'validation')\n",
    "# plt.legend()\n",
    "# plt.xlabel('epochs')\n",
    "# plt.ylabel('loss')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# how to load the stored model\n",
    "\n",
    "# from keras.models import load_model\n",
    "# saved_model = load_model(filepath)\n",
    "# tr_ac = model.evaluate([X_train[:, 0], X_train[:, 1], X_train[:, 2]], to_categorical(y_train))[1]\n",
    "# print(\"train acc--->\", tr_ac)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
