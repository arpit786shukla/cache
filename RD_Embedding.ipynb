{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/nfs_home/nbhardwaj/.local/lib/python3.5/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/nfs_home/nbhardwaj/.local/lib/python3.5/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/nfs_home/nbhardwaj/.local/lib/python3.5/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/nfs_home/nbhardwaj/.local/lib/python3.5/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/nfs_home/nbhardwaj/.local/lib/python3.5/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/nfs_home/nbhardwaj/.local/lib/python3.5/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/nfs_home/nbhardwaj/.local/lib/python3.5/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/nfs_home/nbhardwaj/.local/lib/python3.5/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/nfs_home/nbhardwaj/.local/lib/python3.5/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/nfs_home/nbhardwaj/.local/lib/python3.5/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/nfs_home/nbhardwaj/.local/lib/python3.5/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/nfs_home/nbhardwaj/.local/lib/python3.5/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import defaultdict \n",
    "import sys\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from tabulate import tabulate\n",
    "\n",
    "import keras \n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, Input, Dropout, Embedding, LSTM, Flatten, Lambda\n",
    "from sklearn.preprocessing import OneHotEncoder, MinMaxScaler\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "\n",
    "from keras.utils import to_categorical\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from keras.utils.vis_utils import plot_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "ADDR = '/nfs_home/nbhardwaj/data/rds_data/400/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "class LabelEncoderExt(object):\n",
    "    def __init__(self):\n",
    "        \"\"\"\n",
    "        It differs from LabelEncoder by handling new classes and providing a value for it [Unknown]\n",
    "        Unknown will be added in fit and transform will take care of new item. It gives unknown class id\n",
    "        \"\"\"\n",
    "        self.label_encoder = LabelEncoder()\n",
    "        # self.classes_ = self.label_encoder.classes_\n",
    "\n",
    "    def fit(self, data_list):\n",
    "        \"\"\"\n",
    "        This will fit the encoder for all the unique values and introduce unknown value\n",
    "        :param data_list: A list of string\n",
    "        :return: self\n",
    "        \"\"\"\n",
    "        self.label_encoder = self.label_encoder.fit(list(data_list) + ['Unknown'])\n",
    "        self.classes_ = self.label_encoder.classes_\n",
    "\n",
    "        return self\n",
    "\n",
    "    def transform(self, data_list):\n",
    "        \"\"\"\n",
    "        This will transform the data_list to id list where the new values get assigned to Unknown class\n",
    "        :param data_list:\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        new_data_list = list(data_list)\n",
    "        for unique_item in np.unique(data_list):\n",
    "            if unique_item not in self.label_encoder.classes_:\n",
    "                new_data_list = ['Unknown' if x==unique_item else x for x in new_data_list]\n",
    "\n",
    "        return self.label_encoder.transform(new_data_list)\n",
    "    \n",
    "    \n",
    "def create_model(embed_size = 10):\n",
    "        inp1 = Input(shape = (1,))\n",
    "        inp2 = Input(shape = (1,))\n",
    "        inp3 = Input(shape = (1,))\n",
    "\n",
    "        embed1 = Embedding(len(le_inst.classes_), embed_size, input_length = 1)(inp1)\n",
    "        embed2 = Embedding(len(le_delta.classes_), embed_size, input_length = 1)(inp2)\n",
    "\n",
    "        merged_inp = keras.layers.concatenate([embed1, embed2], axis = 1)\n",
    "        merged_inp = Flatten()(merged_inp)\n",
    "        merged_inp = keras.layers.concatenate([merged_inp, inp3])\n",
    "\n",
    "        out = Dense(200, activation = 'relu')(merged_inp)\n",
    "        out = Dense(8, activation = 'softmax')(out)\n",
    "\n",
    "        model = Model([inp1, inp2, inp3], out)\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/nfs_home/nbhardwaj/.local/lib/python3.5/site-packages/ipykernel_launcher.py:31: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n"
     ]
    }
   ],
   "source": [
    "sets = [x for x in range(64)]\n",
    "inst_vocab = []\n",
    "delta_vocal = []\n",
    "train_acc = []\n",
    "test_acc = []\n",
    "for cset in sets:\n",
    "    df = pd.read_csv(ADDR+str(cset)+'.csv', index_col = [0])\n",
    "    df.Mode = np.where(df.Mode.values=='R', 1, -1)\n",
    "    # df.Mode = df['Mode'].astype('str')\n",
    "    # df.Instruction = df.Instruction.astype('str')\n",
    "    # df.delta = df.delta.astype('float')\n",
    "    df.label = df.label - 1\n",
    "    X = df[['Instruction', 'delta', 'Mode']].values[1:]\n",
    "    y = df[['label']].values[1:]\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.33, random_state = 42)\n",
    "\n",
    "    le_inst = LabelEncoderExt()\n",
    "    le_inst.fit(X_train[:, 0])\n",
    "    le_delta = LabelEncoderExt()\n",
    "    le_delta.fit(X_train[:, 1])\n",
    "\n",
    "    X_train[:, 0] = le_inst.transform(X_train[:, 0])\n",
    "    X_train[:, 1] = le_delta.transform(X_train[:, 1])\n",
    "\n",
    "    X_test[:, 0] = le_inst.transform(X_test[:, 0])\n",
    "    X_test[:, 1] = le_delta.transform(X_test[:, 1])\n",
    "    \n",
    "    model = create_model()\n",
    "    model.compile(optimizer = 'adam', loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
    "    filepath = '/nfs_home/nbhardwaj/model_weights/RD_Embedding/'+str(cset)+'.hdf5'\n",
    "    # checkpointer = ModelCheckpoint(filepath, monitor = 'val_acc', save_best_only = True, mode = 'max', verbose = 1)\n",
    "    model.fit([X_train[:, 0], X_train[:, 1], X_train[:, 2]], to_categorical(y_train), epochs = 10)\n",
    "    model.save_weights(filepath)\n",
    "    t_ac = model.evaluate([X_test[:, 0], X_test[:, 1], X_test[:, 2]], to_categorical(y_test))[1]\n",
    "    test_acc.append(t_ac)\n",
    "    train_acc.append(model.evaluate([X_train[:, 0], X_train[:, 1], X_train[:, 2]], to_categorical(y_train))[1])\n",
    "    inst_vocab.append(len(le_inst.classes_))\n",
    "    delta_vocab.append(len(le_delta.classes_))\n",
    "    print(\"--------------done processing for set---------->\", cset, '|| accuracy||', t_ac)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ICount</th>\n",
       "      <th>Instruction</th>\n",
       "      <th>Data</th>\n",
       "      <th>Mode</th>\n",
       "      <th>set</th>\n",
       "      <th>rd</th>\n",
       "      <th>delta</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>638313090423</td>\n",
       "      <td>4722720</td>\n",
       "      <td>2198847782096</td>\n",
       "      <td>R</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>638313090428</td>\n",
       "      <td>4722742</td>\n",
       "      <td>3646153</td>\n",
       "      <td>R</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>-2.198844e+12</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>638313090748</td>\n",
       "      <td>4722720</td>\n",
       "      <td>2198847782096</td>\n",
       "      <td>R</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2.198844e+12</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>638313090753</td>\n",
       "      <td>4722742</td>\n",
       "      <td>3646153</td>\n",
       "      <td>R</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>-2.198844e+12</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>638313091064</td>\n",
       "      <td>4722720</td>\n",
       "      <td>2198847782096</td>\n",
       "      <td>R</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2.198844e+12</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         ICount  Instruction           Data Mode  set  rd         delta  label\n",
       "0  638313090423      4722720  2198847782096    R    0   2           NaN      2\n",
       "1  638313090428      4722742        3646153    R    0   2 -2.198844e+12      2\n",
       "2  638313090748      4722720  2198847782096    R    0   2  2.198844e+12      2\n",
       "3  638313090753      4722742        3646153    R    0   2 -2.198844e+12      2\n",
       "4  638313091064      4722720  2198847782096    R    0   2  2.198844e+12      2"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# df.head()\n",
    "\n",
    "# # Read -> 1 ; Write -> -1\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# print(np.min(df.Instruction.values), np.max(df.Instruction.values))\n",
    "\n",
    "# print(X.shape, y.shape, X_train.shape, y_train.shape, X_test.shape, y_test.shape)\n",
    "\n",
    "# print(len(np.unique(X_train[:, 0])), len(np.unique(X[:, 0])), len(np.unique(X_train[:, 1])), len(np.unique(X[:, 1])))\n",
    "\n",
    "\n",
    "\n",
    "# le_inst = LabelEncoderExt()\n",
    "# le_inst.fit(X_train[:, 0])\n",
    "# le_delta = LabelEncoderExt()\n",
    "# le_delta.fit(X_train[:, 1])\n",
    "\n",
    "# X_train[:, 0] = le_inst.transform(X_train[:, 0])\n",
    "# X_train[:, 1] = le_delta.transform(X_train[:, 1])\n",
    "\n",
    "# X_test[:, 0] = le_inst.transform(X_test[:, 0])\n",
    "# X_test[:, 1] = le_delta.transform(X_test[:, 1])\n",
    "\n",
    "# print(len(le_inst.classes_), len(le_delta.classes_))\n",
    "\n",
    "# def create_model(embed_size = 10):\n",
    "#     inp1 = Input(shape = (1,))\n",
    "#     inp2 = Input(shape = (1,))\n",
    "#     inp3 = Input(shape = (1,))\n",
    "\n",
    "#     embed1 = Embedding(len(le_inst.classes_), embed_size, input_length = 1)(inp1)\n",
    "#     embed2 = Embedding(len(le_delta.classes_), embed_size, input_length = 1)(inp2)\n",
    "    \n",
    "#     merged_inp = keras.layers.concatenate([embed1, embed2], axis = 1)\n",
    "#     merged_inp = Flatten()(merged_inp)\n",
    "#     merged_inp = keras.layers.concatenate([merged_inp, inp3])\n",
    "    \n",
    "#     out = Dense(200, activation = 'relu')(merged_inp)\n",
    "#     out = Dense(8, activation = 'softmax')(out)\n",
    "    \n",
    "#     model = Model([inp1, inp2, inp3], out)\n",
    "#     return model\n",
    "    \n",
    "\n",
    "# model = create_model()\n",
    "\n",
    "# print(model.summary())\n",
    "\n",
    "# plot_model(model)\n",
    "\n",
    "# model.compile(optimizer = 'adam', loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
    "\n",
    "# filepath = '/nfs_home/nbhardwaj/model_weights/RD_Embedding/'+str(cset)+'.hdf5'\n",
    "\n",
    "# # checkpointer = ModelCheckpoint(filepath, monitor = 'val_acc', save_best_only = True, mode = 'max', verbose = 1)\n",
    "# model.fit([X_train[:, 0], X_train[:, 1], X_train[:, 2]], to_categorical(y_train), epochs = 2)\n",
    "\n",
    "\n",
    "# model.save_weights(filepath)\n",
    "\n",
    "# acc_test = model.evaluate([X_test[:, 0], X_test[:, 1], X_test[:, 2]], to_categorical(y_test))\n",
    "\n",
    "# print(acc_test[0])\n",
    "# print(model.metrics_names)\n",
    "\n",
    "# len(le_inst.classes_)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
