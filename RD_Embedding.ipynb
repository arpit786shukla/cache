{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import defaultdict \n",
    "import sys\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from tabulate import tabulate\n",
    "\n",
    "import keras \n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, Input, Dropout, Embedding, LSTM, Flatten, Lambda\n",
    "from sklearn.preprocessing import OneHotEncoder, MinMaxScaler\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "\n",
    "from keras.utils import to_categorical\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from keras.utils.vis_utils import plot_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "ADDR = '/nfs_home/nbhardwaj/data/rds_data/SPEC2017/'\n",
    "files = [510]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "class LabelEncoderExt(object):\n",
    "    def __init__(self):\n",
    "        \"\"\"\n",
    "        It differs from LabelEncoder by handling new classes and providing a value for it [Unknown]\n",
    "        Unknown will be added in fit and transform will take care of new item. It gives unknown class id\n",
    "        \"\"\"\n",
    "        self.label_encoder = LabelEncoder()\n",
    "        # self.classes_ = self.label_encoder.classes_\n",
    "\n",
    "    def fit(self, data_list):\n",
    "        \"\"\"\n",
    "        This will fit the encoder for all the unique values and introduce unknown value\n",
    "        :param data_list: A list of string\n",
    "        :return: self\n",
    "        \"\"\"\n",
    "        self.label_encoder = self.label_encoder.fit(list(data_list) + ['Unknown'])\n",
    "        self.classes_ = self.label_encoder.classes_\n",
    "\n",
    "        return self\n",
    "\n",
    "    def transform(self, data_list):\n",
    "        \"\"\"\n",
    "        This will transform the data_list to id list where the new values get assigned to Unknown class\n",
    "        :param data_list:\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        new_data_list = list(data_list)\n",
    "        m = {}\n",
    "        for x in self.label_encoder.classes_:\n",
    "            m[x] = True\n",
    "        for ind, y in enumerate(new_data_list):\n",
    "            if(m.get(y) is None):\n",
    "                new_data_list[ind] = 'Unknown'\n",
    "#         for unique_item in np.unique(data_list):\n",
    "#             if unique_item not in self.label_encoder.classes_:\n",
    "#                 new_data_list = ['Unknown' if x==unique_item else x for x in new_data_list]\n",
    "        return self.label_encoder.transform(new_data_list)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(embed_size = 10, dense_size = 200):\n",
    "    inp1 = Input(shape = (1,))\n",
    "#     inp2 = Input(shape = (1,))\n",
    "#     inp3 = Input(shape = (1,))\n",
    "\n",
    "    embed1 = Embedding(len(le_inst.classes_), embed_size, input_length = 1)(inp1)\n",
    "#     embed2 = Embedding(len(le_delta.classes_), embed_size, input_length = 1)(inp2)\n",
    "\n",
    "#     merged_inp = keras.layers.concatenate([embed1, embed2], axis = 1)\n",
    "    merged_inp = Flatten()(embed1)\n",
    "#     merged_inp = keras.layers.concatenate([merged_inp, inp3])\n",
    "\n",
    "    out = Dense(dense_size, activation = 'relu')(merged_inp)\n",
    "    out = Dense(8, activation = 'softmax')(out)\n",
    "\n",
    "    model = Model([inp1], out)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------split done---------------------\n",
      "----------------labels done----------------------\n",
      "--------\n",
      "-------------------labels transformed---------------------\n",
      "Epoch 1/2\n",
      "1889/1889 [==============================] - 1s 737us/step - loss: 1.9467 - accuracy: 0.3875\n",
      "Epoch 2/2\n",
      "1889/1889 [==============================] - 0s 110us/step - loss: 1.5158 - accuracy: 0.5437\n",
      "------------training done------------\n",
      "931/931 [==============================] - 1s 697us/step\n",
      "1889/1889 [==============================] - 0s 64us/step\n",
      "--------------done processing for set----------> 0 || accuracy|| 0.6036520004272461\n",
      "--------------------split done---------------------\n",
      "----------------labels done----------------------\n",
      "--------\n",
      "-------------------labels transformed---------------------\n",
      "Epoch 1/2\n",
      "1068/1068 [==============================] - 1s 700us/step - loss: 2.0113 - accuracy: 0.4213\n",
      "Epoch 2/2\n",
      "1068/1068 [==============================] - 0s 93us/step - loss: 1.7624 - accuracy: 0.5346\n",
      "------------training done------------\n",
      "527/527 [==============================] - 1s 1ms/step\n",
      "1068/1068 [==============================] - 0s 62us/step\n",
      "--------------done processing for set----------> 1 || accuracy|| 0.6394686698913574\n",
      "--------------------split done---------------------\n",
      "----------------labels done----------------------\n",
      "--------\n",
      "-------------------labels transformed---------------------\n",
      "Epoch 1/2\n",
      "1514/1514 [==============================] - 1s 553us/step - loss: 1.9607 - accuracy: 0.4287\n",
      "Epoch 2/2\n",
      "1514/1514 [==============================] - 0s 109us/step - loss: 1.5401 - accuracy: 0.4465\n",
      "------------training done------------\n",
      "746/746 [==============================] - 1s 832us/step\n",
      "1514/1514 [==============================] - 0s 61us/step\n",
      "--------------done processing for set----------> 2 || accuracy|| 0.479892760515213\n",
      "--------------------split done---------------------\n",
      "----------------labels done----------------------\n",
      "--------\n",
      "-------------------labels transformed---------------------\n",
      "Epoch 1/2\n",
      "690/690 [==============================] - 1s 1ms/step - loss: 2.0456 - accuracy: 0.2971\n",
      "Epoch 2/2\n",
      "690/690 [==============================] - 0s 123us/step - loss: 1.9393 - accuracy: 0.4391\n",
      "------------training done------------\n",
      "341/341 [==============================] - 1s 2ms/step\n",
      "690/690 [==============================] - 0s 64us/step\n",
      "--------------done processing for set----------> 3 || accuracy|| 0.46041056513786316\n",
      "--------------------split done---------------------\n",
      "----------------labels done----------------------\n",
      "--------\n",
      "-------------------labels transformed---------------------\n",
      "Epoch 1/2\n",
      "1293/1293 [==============================] - 1s 600us/step - loss: 2.0371 - accuracy: 0.1887\n",
      "Epoch 2/2\n",
      "1293/1293 [==============================] - 0s 103us/step - loss: 1.8584 - accuracy: 0.3774\n",
      "------------training done------------\n",
      "638/638 [==============================] - 1s 1ms/step\n",
      "1293/1293 [==============================] - 0s 61us/step\n",
      "--------------done processing for set----------> 4 || accuracy|| 0.5156739950180054\n",
      "--------------------split done---------------------\n",
      "----------------labels done----------------------\n",
      "--------\n",
      "-------------------labels transformed---------------------\n",
      "Epoch 1/2\n",
      "85221/85221 [==============================] - 10s 112us/step - loss: 0.3139 - accuracy: 0.9099\n",
      "Epoch 2/2\n",
      "85221/85221 [==============================] - 9s 103us/step - loss: 0.2631 - accuracy: 0.9123\n",
      "------------training done------------\n",
      "41975/41975 [==============================] - 3s 80us/step\n",
      "85221/85221 [==============================] - 6s 67us/step\n",
      "--------------done processing for set----------> 5 || accuracy|| 0.9122096300125122\n",
      "--------------------split done---------------------\n",
      "----------------labels done----------------------\n",
      "--------\n",
      "-------------------labels transformed---------------------\n",
      "Epoch 1/2\n",
      "1477/1477 [==============================] - 1s 562us/step - loss: 2.0020 - accuracy: 0.2803\n",
      "Epoch 2/2\n",
      "1477/1477 [==============================] - 0s 114us/step - loss: 1.7237 - accuracy: 0.3487\n",
      "------------training done------------\n",
      "728/728 [==============================] - 1s 909us/step\n",
      "1477/1477 [==============================] - 0s 65us/step\n",
      "--------------done processing for set----------> 6 || accuracy|| 0.46291208267211914\n",
      "--------------------split done---------------------\n",
      "----------------labels done----------------------\n",
      "--------\n",
      "-------------------labels transformed---------------------\n",
      "Epoch 1/2\n",
      "1331/1331 [==============================] - 1s 626us/step - loss: 1.9858 - accuracy: 0.3636\n",
      "Epoch 2/2\n",
      "1331/1331 [==============================] - 0s 104us/step - loss: 1.6976 - accuracy: 0.4711\n",
      "------------training done------------\n",
      "657/657 [==============================] - 1s 1ms/step\n",
      "1331/1331 [==============================] - 0s 62us/step\n",
      "--------------done processing for set----------> 7 || accuracy|| 0.49619483947753906\n",
      "--------------------split done---------------------\n",
      "----------------labels done----------------------\n",
      "--------\n",
      "-------------------labels transformed---------------------\n",
      "Epoch 1/2\n",
      "49006/49006 [==============================] - 6s 119us/step - loss: 0.2840 - accuracy: 0.9237\n",
      "Epoch 2/2\n",
      "49006/49006 [==============================] - 5s 103us/step - loss: 0.2141 - accuracy: 0.9289\n",
      "------------training done------------\n",
      "24138/24138 [==============================] - 2s 92us/step\n",
      "49006/49006 [==============================] - 3s 67us/step\n",
      "--------------done processing for set----------> 8 || accuracy|| 0.9317673444747925\n",
      "--------------------split done---------------------\n",
      "----------------labels done----------------------\n",
      "--------\n",
      "-------------------labels transformed---------------------\n",
      "Epoch 1/2\n",
      "1813/1813 [==============================] - 1s 487us/step - loss: 1.9323 - accuracy: 0.5069\n",
      "Epoch 2/2\n",
      "1813/1813 [==============================] - 0s 104us/step - loss: 1.3262 - accuracy: 0.6045\n",
      "------------training done------------\n",
      "894/894 [==============================] - 1s 777us/step\n",
      "1813/1813 [==============================] - 0s 64us/step\n",
      "--------------done processing for set----------> 9 || accuracy|| 0.7438478469848633\n",
      "--------------------split done---------------------\n",
      "----------------labels done----------------------\n",
      "--------\n",
      "-------------------labels transformed---------------------\n",
      "Epoch 1/2\n",
      "3888/3888 [==============================] - 1s 289us/step - loss: 1.5921 - accuracy: 0.5967\n",
      "Epoch 2/2\n",
      "3888/3888 [==============================] - 0s 97us/step - loss: 0.8223 - accuracy: 0.7233\n",
      "------------training done------------\n",
      "1916/1916 [==============================] - 1s 406us/step\n",
      "3888/3888 [==============================] - 0s 66us/step\n",
      "--------------done processing for set----------> 10 || accuracy|| 0.7400835156440735\n",
      "--------------------split done---------------------\n",
      "----------------labels done----------------------\n",
      "--------\n",
      "-------------------labels transformed---------------------\n",
      "Epoch 1/2\n",
      "19435/19435 [==============================] - 3s 141us/step - loss: 0.7394 - accuracy: 0.7786\n",
      "Epoch 2/2\n",
      "19435/19435 [==============================] - 2s 102us/step - loss: 0.5316 - accuracy: 0.8290\n",
      "------------training done------------\n",
      "9573/9573 [==============================] - 1s 134us/step\n",
      "19435/19435 [==============================] - 1s 68us/step\n",
      "--------------done processing for set----------> 11 || accuracy|| 0.8329676985740662\n",
      "--------------------split done---------------------\n",
      "----------------labels done----------------------\n",
      "--------\n",
      "-------------------labels transformed---------------------\n",
      "Epoch 1/2\n",
      "23655298/23655298 [==============================] - 2462s 104us/step - loss: 0.2521 - accuracy: 0.9166\n",
      "Epoch 2/2\n",
      "51287584/90914766 [===============>..............] - ETA: 47:38"
     ]
    }
   ],
   "source": [
    "sets = [x for x in range(64)]\n",
    "inst_vocab = []\n",
    "delta_vocab = []\n",
    "train_acc = []\n",
    "test_acc = []\n",
    "for cset in sets:\n",
    "    df = pd.read_csv(ADDR+'510_'+str(cset)+'.csv', index_col = [0], usecols = [0, 2, 8])\n",
    "#     df.Mode = np.where(df.Mode.values=='R', 1, -1)\n",
    "#     df.Mode = df['Mode'].astype('str')\n",
    "    df.Instruction = df.Instruction.astype('str')\n",
    "#     df.delta = df.delta.astype('float')\n",
    "#     X = df[['Instruction', 'delta', 'Mode']].values[1:]\n",
    "    X = df[['Instruction']].values\n",
    "    y = df[['label']].values\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.33, random_state = 42)\n",
    "    print(\"--------------------split done---------------------\")\n",
    "    le_inst = LabelEncoderExt()\n",
    "    le_inst.fit(X_train[:, 0])\n",
    "#     le_delta = LabelEncoderExt()\n",
    "#     le_delta.fit(X_train[:, 1])\n",
    "    print(\"----------------labels done----------------------\")\n",
    "    X_train[:, 0] = le_inst.transform(X_train[:, 0])\n",
    "#     X_train[:, 1] = le_delta.transform(X_train[:, 1])\n",
    "    print(\"--------\")\n",
    "    \n",
    "    X_test[:, 0] = le_inst.transform(X_test[:, 0])\n",
    "#     X_test[:, 1] = le_delta.transform(X_test[:, 1])\n",
    "    print(\"-------------------labels transformed---------------------\")\n",
    "    model = create_model()\n",
    "    model.compile(optimizer = 'adam', loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
    "    filepath = '/nfs_home/nbhardwaj/model_weights/SPEC2017/510_'+str(cset)+'.hdf5'\n",
    "    # checkpointer = ModelCheckpoint(filepath, monitor = 'val_acc', save_best_only = True, mode = 'max', verbose = 1)\n",
    "    model.fit(X_train[:, 0] , to_categorical(y_train), epochs = 2, use_multiprocessing = True)\n",
    "    print(\"------------training done------------\")\n",
    "    model.save_weights(filepath)\n",
    "    t_ac = model.evaluate(X_test[:, 0], to_categorical(y_test))[1]\n",
    "    test_acc.append(t_ac)\n",
    "    train_acc.append(model.evaluate(X_train[:, 0], to_categorical(y_train))[1])\n",
    "    inst_vocab.append(len(le_inst.classes_))\n",
    "#     delta_vocab.append(len(le_delta.classes_))\n",
    "    print(\"--------------done processing for set---------->\", cset, '|| accuracy||', t_ac)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.6036520004272461,\n",
       " 0.6394686698913574,\n",
       " 0.479892760515213,\n",
       " 0.46041056513786316,\n",
       " 0.5156739950180054,\n",
       " 0.9122096300125122,\n",
       " 0.46291208267211914,\n",
       " 0.49619483947753906,\n",
       " 0.9317673444747925,\n",
       " 0.7438478469848633,\n",
       " 0.7400835156440735,\n",
       " 0.8329676985740662,\n",
       " 0.91651451587677,\n",
       " 0.8276474475860596,\n",
       " 0.8748176097869873,\n",
       " 0.8744987845420837,\n",
       " 0.9370473623275757,\n",
       " 0.8140120506286621,\n",
       " 0.8759154677391052,\n",
       " 0.8749029040336609,\n",
       " 0.6692717671394348,\n",
       " 0.8526544570922852,\n",
       " 0.9171963930130005,\n",
       " 0.8150568008422852,\n",
       " 0.7618939876556396,\n",
       " 0.874782383441925,\n",
       " 0.8873749375343323,\n",
       " 0.701298713684082,\n",
       " 0.6073619723320007,\n",
       " 0.8744004964828491,\n",
       " 0.6280087232589722,\n",
       " 0.4568965435028076,\n",
       " 0.7677642703056335,\n",
       " 0.31351351737976074,\n",
       " 0.4261603355407715,\n",
       " 0.7698503732681274,\n",
       " 0.781074583530426,\n",
       " 0.7668323516845703,\n",
       " 0.435546875,\n",
       " 0.7782971858978271,\n",
       " 0.5431917905807495,\n",
       " 0.788249671459198,\n",
       " 0.692650318145752,\n",
       " 0.984354555606842,\n",
       " 0.7985031604766846,\n",
       " 0.5134680271148682,\n",
       " 0.49293285608291626,\n",
       " 0.42032331228256226,\n",
       " 0.6212424635887146,\n",
       " 0.9843252301216125,\n",
       " 0.5906344652175903,\n",
       " 0.3253731429576874,\n",
       " 0.5680473446846008,\n",
       " 0.6116611957550049,\n",
       " 0.8723942041397095,\n",
       " 0.8750447034835815,\n",
       " 0.7822476029396057,\n",
       " 0.7851027250289917,\n",
       " 0.7911374568939209,\n",
       " 0.9495806097984314,\n",
       " 0.882443904876709,\n",
       " 0.6155115365982056,\n",
       " 0.7335907220840454,\n",
       " 0.5791583061218262]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "64"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(inst_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------labels transformed---------------------\n",
      "WARNING:tensorflow:From /nfs_home/nbhardwaj/.local/lib/python3.5/site-packages/keras/backend/tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "Epoch 1/2\n",
      "178847/178847 [==============================] - 14s 80us/step - loss: 0.3742 - accuracy: 0.8792\n",
      "Epoch 2/2\n",
      "178847/178847 [==============================] - 14s 78us/step - loss: 0.3279 - accuracy: 0.8919\n",
      "------------training done------------\n",
      "88089/88089 [==============================] - 3s 34us/step\n",
      "178847/178847 [==============================] - 6s 34us/step\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'delta_vocab' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-b35011eaee2e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mtrain_acc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mto_categorical\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0minst_vocab\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mle_inst\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclasses_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0mdelta_vocab\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mle_delta\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclasses_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"--------------done processing for set---------->\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'|| accuracy||'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt_ac\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'delta_vocab' is not defined"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ICount</th>\n",
       "      <th>Instruction</th>\n",
       "      <th>Data</th>\n",
       "      <th>Mode</th>\n",
       "      <th>set</th>\n",
       "      <th>rd</th>\n",
       "      <th>delta</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>638313090423</td>\n",
       "      <td>4722720</td>\n",
       "      <td>2198847782096</td>\n",
       "      <td>R</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>638313090428</td>\n",
       "      <td>4722742</td>\n",
       "      <td>3646153</td>\n",
       "      <td>R</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>-2.198844e+12</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>638313090748</td>\n",
       "      <td>4722720</td>\n",
       "      <td>2198847782096</td>\n",
       "      <td>R</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2.198844e+12</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>638313090753</td>\n",
       "      <td>4722742</td>\n",
       "      <td>3646153</td>\n",
       "      <td>R</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>-2.198844e+12</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>638313091064</td>\n",
       "      <td>4722720</td>\n",
       "      <td>2198847782096</td>\n",
       "      <td>R</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2.198844e+12</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         ICount  Instruction           Data Mode  set  rd         delta  label\n",
       "0  638313090423      4722720  2198847782096    R    0   2           NaN      2\n",
       "1  638313090428      4722742        3646153    R    0   2 -2.198844e+12      2\n",
       "2  638313090748      4722720  2198847782096    R    0   2  2.198844e+12      2\n",
       "3  638313090753      4722742        3646153    R    0   2 -2.198844e+12      2\n",
       "4  638313091064      4722720  2198847782096    R    0   2  2.198844e+12      2"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# df.head()\n",
    "\n",
    "# # Read -> 1 ; Write -> -1\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# print(np.min(df.Instruction.values), np.max(df.Instruction.values))\n",
    "\n",
    "# print(X.shape, y.shape, X_train.shape, y_train.shape, X_test.shape, y_test.shape)\n",
    "\n",
    "# print(len(np.unique(X_train[:, 0])), len(np.unique(X[:, 0])), len(np.unique(X_train[:, 1])), len(np.unique(X[:, 1])))\n",
    "\n",
    "\n",
    "\n",
    "# le_inst = LabelEncoderExt()\n",
    "# le_inst.fit(X_train[:, 0])\n",
    "# le_delta = LabelEncoderExt()\n",
    "# le_delta.fit(X_train[:, 1])\n",
    "\n",
    "# X_train[:, 0] = le_inst.transform(X_train[:, 0])\n",
    "# X_train[:, 1] = le_delta.transform(X_train[:, 1])\n",
    "\n",
    "# X_test[:, 0] = le_inst.transform(X_test[:, 0])\n",
    "# X_test[:, 1] = le_delta.transform(X_test[:, 1])\n",
    "\n",
    "# print(len(le_inst.classes_), len(le_delta.classes_))\n",
    "\n",
    "# def create_model(embed_size = 10):\n",
    "#     inp1 = Input(shape = (1,))\n",
    "#     inp2 = Input(shape = (1,))\n",
    "#     inp3 = Input(shape = (1,))\n",
    "\n",
    "#     embed1 = Embedding(len(le_inst.classes_), embed_size, input_length = 1)(inp1)\n",
    "#     embed2 = Embedding(len(le_delta.classes_), embed_size, input_length = 1)(inp2)\n",
    "    \n",
    "#     merged_inp = keras.layers.concatenate([embed1, embed2], axis = 1)\n",
    "#     merged_inp = Flatten()(merged_inp)\n",
    "#     merged_inp = keras.layers.concatenate([merged_inp, inp3])\n",
    "    \n",
    "#     out = Dense(200, activation = 'relu')(merged_inp)\n",
    "#     out = Dense(8, activation = 'softmax')(out)\n",
    "    \n",
    "#     model = Model([inp1, inp2, inp3], out)\n",
    "#     return model\n",
    "    \n",
    "\n",
    "# model = create_model()\n",
    "\n",
    "# print(model.summary())\n",
    "\n",
    "# plot_model(model)\n",
    "\n",
    "# model.compile(optimizer = 'adam', loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
    "\n",
    "# filepath = '/nfs_home/nbhardwaj/model_weights/RD_Embedding/'+str(cset)+'.hdf5'\n",
    "\n",
    "# # checkpointer = ModelCheckpoint(filepath, monitor = 'val_acc', save_best_only = True, mode = 'max', verbose = 1)\n",
    "# model.fit([X_train[:, 0], X_train[:, 1], X_train[:, 2]], to_categorical(y_train), epochs = 2)\n",
    "\n",
    "\n",
    "# model.save_weights(filepath)\n",
    "\n",
    "# acc_test = model.evaluate([X_test[:, 0], X_test[:, 1], X_test[:, 2]], to_categorical(y_test))\n",
    "\n",
    "# print(acc_test[0])\n",
    "# print(model.metrics_names)\n",
    "\n",
    "# len(le_inst.classes_)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
